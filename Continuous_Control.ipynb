{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "Train an agent to reach its robot arm to the target!\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "      <td>Single Agent</td>\n",
    "      <td>20 Agents</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"files/images/one_agent.gif\" align=\"center\"></td>\n",
    "    <td><img src=\"files/images/twenty_agents.gif\" align=\"center\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "---\n",
    "* Table of Contents\n",
    "\n",
    "\n",
    "0. [Import Necessary Modules](#0.-Import-Necessary-Modules)\n",
    "1. [Start and Explore the Environment](#1.-Start-and-Explore-the-Environment)\n",
    "    * 1.1. [Start the Environment](#1.1.-Start-the-Environment)\n",
    "    * 1.2. [Examine the State and Action Spaces](#1.2.-Examine-the-State-and-Action-Spaces)\n",
    "    * 1.3. [Take Random Actions in the Environment](#1.3.-Take-Random-Actions-in-the-Environment)\n",
    "2. [It's Your Turn!](#2.-It's-Your-Turn!)\n",
    "    * 1.1. [Tune Your Hyperparameters!](#2.1.-Tune-Your-Hyperparameters!)\n",
    "    * 1.2. [Instantiate Your Agent](#2.2.-Instantiate-Your-Agent)\n",
    "    * 1.3. [Train Your Agent](#2.3.-Train-Your-Agent)\n",
    "    * 1.4. [Plot the Training Scores](#2.4.-Plot-the-Training-Scores)\n",
    "    * 1.5. [Save the Agent](#2.5.-Save-the-Agent)\n",
    "3. [Load & Evaluate the Agent](#3.-Load-&-Evaluate-Your/Pretrained-Agent)\n",
    "    * 1.1. [Load the Agent](#3.1.-Load-the-Agent)\n",
    "    * 1.2. [Watch the Agent!](#3.2.-Watch-the-Agent!)\n",
    "    * 1.3. [More Accurate Evaluation](#3.3.-More-Accurate-Evaluation)\n",
    "4. [Finishing Up](#4.-Finishing-Up)\n",
    "\n",
    "\n",
    "* [Thank You!](##-Thank-you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0.](#Table-of-Contents) Import Necessary Modules\n",
    "---\n",
    "Just run the next cell to prepare all the modules needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:16:31.601664Z",
     "start_time": "2019-04-28T04:16:30.636602Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THE CODE HERE\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "from ddpg_agent import Agent\n",
    "from train import ddpg\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.](#Table-of-Contents) Start and Explore the Environment\n",
    "---\n",
    "In this section, you will load the environment and explore it with random actions. Exploration is optional, but loading the environment is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1.](#Table-of-Contents) Start the Environment\n",
    "---\n",
    "Here, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:16:35.606332Z",
     "start_time": "2019-04-28T04:16:31.604657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(\n",
    "    file_name=\"Reacher_Environment/twenty_agents/Reacher_Windows_x86_64/Reacher.exe\",    # <--- File Path to the Environment file\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# DO NOT EDIT THE LINES BELOW\n",
    "brain_name = env.brain_names[0]\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "action_size = env.brains[brain_name].vector_action_space_size\n",
    "state_size = env_info.vector_observations.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.](#Table-of-Contents) Examine the State and Action Spaces\n",
    "---\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of the agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:16:35.618308Z",
     "start_time": "2019-04-28T04:16:35.608327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "\n",
      "Size of each action: 4\n",
      "\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like:\n",
      " [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n",
      "\n",
      "\n",
      "Shapes:\n",
      "rewards 20\n",
      "vector_observations (20, 33)\n",
      "local_done 20\n"
     ]
    }
   ],
   "source": [
    "# number of agents\n",
    "print('Number of agents:', num_agents, end='\\n\\n')\n",
    "\n",
    "# size of each action\n",
    "print('Size of each action:', action_size, end='\\n\\n')\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:\\n', states[0], end='\\n\\n')\n",
    "print('\\nShapes:')\n",
    "print(\"rewards\", len(env_info.rewards))\n",
    "print(\"vector_observations\", env_info.vector_observations.shape)\n",
    "print(\"local_done\", len(env_info.local_done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.](#Table-of-Contents) Take Random Actions in the Environment\n",
    "---\n",
    "In the next code cell, you will watch the agent's performance when it selects an action at random with each time step. You should be able to observe the agent on the window as it moves through the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:17:55.880543Z",
     "start_time": "2019-04-28T04:16:35.620890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.07749999826774001\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.](#Table-of-Contents) It's Your Turn!\n",
    "---\n",
    "Here, you can train your own agent to solve the environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.1.](#Table-of-Contents) Tune Your Hyperparameters!\n",
    "---\n",
    "All necessary hyperparameters and training parameters for the agent are provided below. Try fiddling with the values to get a better performance out of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:17:55.890492Z",
     "start_time": "2019-04-28T04:17:55.882512Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    # Reproducibility\n",
    "    'seed'                : 0,        # random seed for reproducible results\n",
    "    \n",
    "    # Agent basic parameters\n",
    "    'batch_size'          : 256,      # batch size for each learning step\n",
    "    'buffer_size'         : int(1e6), # up to how many recent experiences to keep\n",
    "    'start_since'         : 256,      # how many experiences to collect before starting learning\n",
    "    'gamma'               : 0.99,     # discount factor\n",
    "    'update_every'        : 1,        # update step frequency\n",
    "    'n_updates'           : 10,       # number of updates per update step\n",
    "    'tau'                 : 1e-3,     # soft-update parameter [0, 1]\n",
    "    \n",
    "    'actor_lr'            : 5e-4,     # learning rate for the actor network\n",
    "    'critic_lr'           : 5e-4,     # learning rate for the critic network\n",
    "    'clip'                : 1,        # gradient clipping to prevent gradient spikes\n",
    "    'weight_decay'        : 0,        # weight decay for the *critic* network\n",
    "\n",
    "    'distributional'      : True,     # whether to use distributional learning\n",
    "\n",
    "    # Prioritized Experience Replay Parameters\n",
    "    'priority_eps'        : 1e-3,     # base priority in order to ensure nonzero priorities\n",
    "    'a'                   : 1.,       # priority exponent parameter [0, 1]\n",
    "\n",
    "    # n-step Bootstrap Target parameter\n",
    "    'n_multisteps'        : 4,        # number of steps to bootstrap\n",
    "    'separate_experiences': False,    # whether to store experiences with no overlap\n",
    "\n",
    "    # Distributional Learning parameters\n",
    "    'v_min'               : 0,        # minimum value for support\n",
    "    'v_max'               : 10,       # maximum value for support\n",
    "    'n_atoms'             : 51,       # number of atoms for distribution\n",
    "\n",
    "    # Noisy Layer parameters\n",
    "    'initial_sigma'       : 0.050,    # initial noisy parameter value\n",
    "    'linear_type'         : 'noisy',  # either 'linear' or 'noisy'\n",
    "    'factorized'          : False     # whether to use factorized gaussian noise or not(independent gaussian noise)\n",
    "}\n",
    "\n",
    "### -------------------------------------------------------------------------------------------------------------- ###\n",
    "\n",
    "train_params = {\n",
    "    'n_episodes'           : 200,   # number of total episodes to train\n",
    "    'continue_after_solved': False, # whether to keep training even after the environment is solved\n",
    "    \n",
    "    # Exploration using gaussian noise\n",
    "    'eps_start'            : 0.0,   # initial epsilon value\n",
    "    'eps_min'              : 0.0,   # minimum value for epsilon\n",
    "    'eps_decay'            : 0.0,   # epsilon decay rate\n",
    "\n",
    "    # Importance-Sampling Weight parameter for Prioritized Experience Replay\n",
    "    'beta_start'           : 1.,    # starting value \n",
    "    'beta_end'             : 1.     # end value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.2.](#Table-of-Contents) Instantiate Your Agent\n",
    "---\n",
    "After tuning your hyperparameters, the agent instance must be created.\n",
    "\n",
    "To do so, simply run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T04:17:58.184875Z",
     "start_time": "2019-04-28T04:17:55.894536Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, num_agents, **hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.3.](#Table-of-Contents) Train Your Agent\n",
    "---\n",
    "With your agent and your training settings, the next cell will run the training session for your agent!\n",
    "\n",
    "(This may take a long time! It can take hours to train a good agent, depending on your PC performance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:57:16.651201Z",
     "start_time": "2019-04-28T04:17:58.186844Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 1 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 2 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 3 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 4 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 5 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 6 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 7 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 8 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 9 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 10 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 11 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 12 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 13 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 14 ***\r",
      "Episode 0 | Total Steps (all agents): 0 | Current Average Score:  0.000 | Last 100 Average Score:  0.000 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 *** timestep 15 ***"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\0107w\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 | Total Steps (all agents): 200200 | Current Average Score: 27.361 | Last 100 Average Score: 13.952 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0191 +- 0.0161*** timestep 1001 ***               \n",
      "Episode 20 | Total Steps (all agents): 400400 | Current Average Score: 39.106 | Last 100 Average Score: 24.946 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0182 +- 0.0156 *** timestep 1001 ***               \n",
      "Episode 30 | Total Steps (all agents): 600600 | Current Average Score: 39.454 | Last 100 Average Score: 29.698 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0206 +- 0.0177 *** timestep 1001 ***               \n",
      "Episode 40 | Total Steps (all agents): 800800 | Current Average Score: 39.159 | Last 100 Average Score: 32.060 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0231 +- 0.0199 *** timestep 1001 ***               \n",
      "Episode 50 | Total Steps (all agents): 1001000 | Current Average Score: 38.923 | Last 100 Average Score: 33.460 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0253 +- 0.0224*** timestep 1001 ***               \n",
      "Episode 60 | Total Steps (all agents): 1201200 | Current Average Score: 39.299 | Last 100 Average Score: 34.416 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0289 +- 0.0267 *** timestep 1001 ***               \n",
      "Episode 70 | Total Steps (all agents): 1401400 | Current Average Score: 39.192 | Last 100 Average Score: 35.020 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0417 +- 0.0378 *** timestep 1001 ***               \n",
      "Episode 80 | Total Steps (all agents): 1601600 | Current Average Score: 39.006 | Last 100 Average Score: 35.533 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0483 +- 0.0435 *** timestep 1001 ***               \n",
      "Episode 90 | Total Steps (all agents): 1801800 | Current Average Score: 39.244 | Last 100 Average Score: 35.938 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0507 +- 0.0460 *** timestep 1001 ***               \n",
      "Episode 100 | Total Steps (all agents): 2002000 | Current Average Score: 39.387 | Last 100 Average Score: 36.256 | Epsilon: 0.0000 | A: 1.0000 | Beta: 1.0000 | Avg Actor Noise Magnitude: 0.0593 +- 0.0533*** timestep 1001 ***               \n",
      "\n",
      "Environment solved in 0 episodes!\tAverage Score: 36.256\n"
     ]
    }
   ],
   "source": [
    "scores = ddpg(env, agent, **train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.4.](#Table-of-Contents) Plot the Training Scores\n",
    "---\n",
    "The code cell below will plot the scores your agent received during its training.\n",
    "\n",
    "This allows you to see your agent's learning performance at a glance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:57:17.362541Z",
     "start_time": "2019-04-28T15:57:16.653195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 4), facecolor='lightsteelblue')\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True)\n",
    "ax.set_facecolor('slategray')\n",
    "ax.plot(np.arange(len(scores)), scores,\n",
    "        alpha=0.7, linewidth=2, color=\"blue\", label=\"Raw Train Score\")\n",
    "ax.plot(np.arange(len(scores)), np.array([np.mean(scores[max(0,i-100):i]) for i in range(1, len(scores)+1)]),\n",
    "        alpha=0.7, linewidth=2, color=\"orange\", label=\"Mean Score over up to 100 Episodes\")\n",
    "ax.legend()\n",
    "xlim = ax.get_xlim()\n",
    "ax.plot(xlim, (30, 30), color=\"black\")\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylabel('Average Score')\n",
    "ax.set_xlabel('Episode #');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.5.](#Table-of-Contents) Save the Agent\n",
    "---\n",
    "If you are satisfied with your agent, you would want to save the agent, scores, and your hyperparameter settings so that it won't be lost.\n",
    "\n",
    "**_Before running the cell below_**, change the file name parameter `f` to the file name you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:57:47.026856Z",
     "start_time": "2019-04-28T15:57:46.705717Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(\n",
    "\n",
    "    f='pretrained.pth',    # <--- Name of the save\n",
    "\n",
    "    obj={'hyperparams': hyperparams, 'train_params': train_params,\n",
    "         'train_scores': scores,\n",
    "         'actor_dict': agent.actor_local.state_dict(),\n",
    "         'critic_dict': agent.critic_local.state_dict()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.](#Table-of-Contents) Load & Evaluate Your/Pretrained Agent\n",
    "---\n",
    "Once the training is done and you want to test your agent, or if you want to see how well my agent performs, you can load the model and run it in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.1.](#Table-of-Contents) Load the Agent\n",
    "---\n",
    "First, you need to load the agent you wish to run, unless the agent is already up and running.\n",
    "\n",
    "**_Before running the next cell_**, change the file name parameter `f` in `torch.load()` to the name of the saved file you want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:57:51.876525Z",
     "start_time": "2019-04-28T15:57:51.768546Z"
    }
   },
   "outputs": [],
   "source": [
    "saved = torch.load(\n",
    "\n",
    "            f=\"pretrained.pth\",    # <--- Name of the file to be loaded\n",
    "\n",
    "            map_location=device\n",
    "\n",
    "        )\n",
    "\n",
    "agent = Agent(state_size, action_size, num_agents, **saved['hyperparams'])\n",
    "agent.actor_local.load_state_dict(saved['actor_dict'])\n",
    "agent.critic_local.load_state_dict(saved['critic_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.2.](#Table-of-Contents) Watch the Agent!\n",
    "---\n",
    "Watch the trained agent performing the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:59:20.189599Z",
     "start_time": "2019-04-28T15:58:00.195934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Average Score at timestep 1001: 39.353499120380734\n",
      "Final Average Score: 39.35349912038073\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "t = 0                                                  # initialize the time step count\n",
    "while True:\n",
    "    actions = agent.act(states)                        # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    t += 1\n",
    "    print(\"\\rCurrent Average Score at timestep {}: {}\".format(t, np.mean(scores)), end='')\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print(\"\\nFinal Average Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3.](#Table-of-Contents) More Accurate Evaluation\n",
    "---\n",
    "To get a better prediction for the agent's performance, you can run multiple episodes and get the average score.\n",
    "\n",
    "Set `n_episodes` in the code cell below to the number of episodes you want to test for, and run the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T16:10:53.778507Z",
     "start_time": "2019-04-28T15:59:20.192591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 | Current Episode Average Score: 39.151 | Previous Episode Average Score: 39.436 | Overall Average Score: 39.310\n",
      "Episode 20 | Current Episode Average Score: 39.458 | Previous Episode Average Score: 39.344 | Overall Average Score: 39.309\n",
      "Episode 30 | Current Episode Average Score: 39.319 | Previous Episode Average Score: 39.357 | Overall Average Score: 39.320\n",
      "Episode 40 | Current Episode Average Score: 38.740 | Previous Episode Average Score: 39.345 | Overall Average Score: 39.333\n",
      "Episode 50 | Current Episode Average Score: 39.320 | Previous Episode Average Score: 39.272 | Overall Average Score: 39.319\n",
      "Episode 60 | Current Episode Average Score: 39.337 | Previous Episode Average Score: 39.409 | Overall Average Score: 39.321\n",
      "Episode 70 | Current Episode Average Score: 39.327 | Previous Episode Average Score: 39.174 | Overall Average Score: 39.317\n",
      "Episode 80 | Current Episode Average Score: 39.328 | Previous Episode Average Score: 39.420 | Overall Average Score: 39.315\n",
      "Episode 90 | Current Episode Average Score: 39.120 | Previous Episode Average Score: 39.375 | Overall Average Score: 39.320\n",
      "Episode 100 | Current Episode Average Score: 39.395 | Previous Episode Average Score: 39.291 | Overall Average Score: 39.315\n",
      "\n",
      "Final Average Score: 39.31585912122205\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 100    # <--- Number of Episodes to test the agent for\n",
    "\n",
    "\n",
    "\n",
    "score_avgs = []\n",
    "report_str_format = \"\\rEpisode {} | Current Episode Average Score: {:.3f} | Previous Episode Average Score: {:.3f} | Overall Average Score: {:.3f}\"\n",
    "for i in range(n_episodes):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = agent.act(states)                        # select an action (for each agent)\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        print(report_str_format.format(i+1, np.mean(scores), score_avgs[-1] if score_avgs else 0, np.mean(score_avgs) if score_avgs else 0), end='')\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    if (i+1) % 10 == 0:\n",
    "        print()\n",
    "    score_avgs.append(np.mean(scores))\n",
    "print(\"\\nFinal Average Score: {}\".format(np.mean(score_avgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4.](#Table-of-Contents) Finishing Up\n",
    "---\n",
    "When you are done, run the cell below to close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T16:10:53.789728Z",
     "start_time": "2019-04-28T16:10:53.780467Z"
    }
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [#](#Table-of-Contents) Thank you!\n",
    "I hope you found something interesting in here. Happy Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
